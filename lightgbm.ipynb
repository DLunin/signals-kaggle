{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import skew\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "#from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "tqdm.pandas()\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../freesound-audio-tagging\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_train_files = os.listdir(os.path.join(data_path, \"audio_train\"))\n",
    "audio_test_files = os.listdir(os.path.join(data_path, \"audio_test\"))\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "submission = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function from EDA kernel: https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis\n",
    "def clean_filename(fname, string):   \n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':        \n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "\n",
    "#returns mfcc features with mean and standard deviation along time\n",
    "def get_mfcc(name, path):\n",
    "    b, _ = librosa.core.load(path + name, sr = SAMPLE_RATE)\n",
    "    assert _ == SAMPLE_RATE\n",
    "    try:\n",
    "        ft1 = librosa.feature.mfcc(b, sr = SAMPLE_RATE, n_mfcc=20)\n",
    "        ft2 = librosa.feature.zero_crossing_rate(b)[0]\n",
    "        ft3 = librosa.feature.spectral_rolloff(b)[0]\n",
    "        ft4 = librosa.feature.spectral_centroid(b)[0]\n",
    "        ft5 = librosa.feature.spectral_contrast(b)[0]\n",
    "        ft6 = librosa.feature.spectral_bandwidth(b)[0]\n",
    "        ft1_trunc = np.hstack((np.mean(ft1, axis=1), np.std(ft1, axis=1), skew(ft1, axis = 1), np.max(ft1, axis = 1), np.min(ft1, axis = 1)))\n",
    "        ft2_trunc = np.hstack((np.mean(ft2), np.std(ft2), skew(ft2), np.max(ft2), np.min(ft2)))\n",
    "        ft3_trunc = np.hstack((np.mean(ft3), np.std(ft3), skew(ft3), np.max(ft3), np.min(ft3)))\n",
    "        ft4_trunc = np.hstack((np.mean(ft4), np.std(ft4), skew(ft4), np.max(ft4), np.min(ft4)))\n",
    "        ft5_trunc = np.hstack((np.mean(ft5), np.std(ft5), skew(ft5), np.max(ft5), np.min(ft5)))\n",
    "        ft6_trunc = np.hstack((np.mean(ft6), np.std(ft6), skew(ft6), np.max(ft6), np.min(ft6)))\n",
    "        return pd.Series(np.hstack((ft1_trunc, ft2_trunc, ft3_trunc, ft4_trunc, ft5_trunc, ft6_trunc)))\n",
    "    except:\n",
    "        raise ValueError\n",
    "        pass\n",
    "    #    print('bad file')\n",
    "    #    return pd.Series([0]*125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "train_data = pd.DataFrame()\n",
    "train_data['fname'] = train['fname']\n",
    "test_data = pd.DataFrame()\n",
    "test_data['fname'] = audio_test_files\n",
    "\n",
    "train_data = train_data['fname'].progress_apply(get_mfcc, path=os.path.join(data_path, \"audio_train/\"))\n",
    "print('done loading train mfcc')\n",
    "test_data = test_data['fname'].progress_apply(get_mfcc, path=os.path.join(data_path, \"audio_test/\"))\n",
    "print('done loading test mfcc')\n",
    "\n",
    "train_data['fname'] = train['fname']\n",
    "test_data['fname'] = audio_test_files\n",
    "train_data['label'] = train['label']\n",
    "test_data['label'] = np.zeros((len(audio_test_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from LightGBM baseline kernel: https://www.kaggle.com/opanichev/lightgbm-baseline\n",
    "# MAPk from https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "\n",
    "\n",
    "def extract_features(files, path):\n",
    "    features = {}\n",
    "\n",
    "    cnt = 0\n",
    "    for f in tqdm(files):\n",
    "        features[f] = {}\n",
    "\n",
    "        fs, data = scipy.io.wavfile.read(os.path.join(path, f))\n",
    "\n",
    "        abs_data = np.abs(data)\n",
    "        diff_data = np.diff(data)\n",
    "\n",
    "        def calc_part_features(data, n=2, prefix=''):\n",
    "            f_i = 1\n",
    "            for i in range(0, len(data), len(data)//n):\n",
    "                features[f]['{}mean_{}_{}'.format(prefix, f_i, n)] = np.mean(data[i:i + len(data)//n])\n",
    "                features[f]['{}std_{}_{}'.format(prefix, f_i, n)] = np.std(data[i:i + len(data)//n])\n",
    "                features[f]['{}min_{}_{}'.format(prefix, f_i, n)] = np.min(data[i:i + len(data)//n])\n",
    "                features[f]['{}max_{}_{}'.format(prefix, f_i, n)] = np.max(data[i:i + len(data)//n])\n",
    "\n",
    "        features[f]['len'] = len(data)\n",
    "        if features[f]['len'] > 0:\n",
    "            n = 1\n",
    "            calc_part_features(data, n=n)\n",
    "            calc_part_features(abs_data, n=n, prefix='abs_')\n",
    "            calc_part_features(diff_data, n=n, prefix='diff_')\n",
    "\n",
    "            n = 2\n",
    "            calc_part_features(data, n=n)\n",
    "            calc_part_features(abs_data, n=n, prefix='abs_')\n",
    "            calc_part_features(diff_data, n=n, prefix='diff_')\n",
    "\n",
    "            n = 3\n",
    "            calc_part_features(data, n=n)\n",
    "            calc_part_features(abs_data, n=n, prefix='abs_')\n",
    "            calc_part_features(diff_data, n=n, prefix='diff_')\n",
    "\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "        # if cnt >= 1000:\n",
    "        #     break\n",
    "\n",
    "    features = pd.DataFrame(features).T.reset_index()\n",
    "    features.rename(columns={'index': 'fname'}, inplace=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "path = os.path.join(data_path, 'audio_train')\n",
    "train_files = train.fname.values\n",
    "train_features = extract_features(train_files, path)\n",
    "\n",
    "path = os.path.join(data_path, 'audio_test')\n",
    "test_files = ss.fname.values\n",
    "test_features = extract_features(test_files, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(train_features, on='fname', how='left')\n",
    "test_data = test_data.merge(test_features, on='fname', how='left')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions from LightGBM baseline: https://www.kaggle.com/opanichev/lightgbm-baseline\n",
    "# Construct features set\n",
    "X = train_data.drop(['label', 'fname'], axis=1)\n",
    "feature_names = list(X.columns)\n",
    "X = X.values\n",
    "labels = np.sort(np.unique(train_data.label.values))\n",
    "num_class = len(labels)\n",
    "c2i = {}\n",
    "i2c = {}\n",
    "for i, c in enumerate(labels):\n",
    "    c2i[c] = i\n",
    "    i2c[i] = c\n",
    "y = np.array([c2i[x] for x in train_data.label.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting xgboost on the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10, shuffle = True)\n",
    "clf = XGBClassifier(max_depth=5, learning_rate=0.05, n_estimators=3000,\n",
    "                    n_jobs=-1, random_state=0, reg_alpha=0.2, \n",
    "                    colsample_bylevel=0.9, colsample_bytree=0.9)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(clf.predict(X_val), y_val))\n",
    "#more functions from LightGBM baseline: https://www.kaggle.com/opanichev/lightgbm-baseline\n",
    "def proba2labels(preds, i2c, k=3):\n",
    "    ans = []\n",
    "    ids = []\n",
    "    for p in preds:\n",
    "        idx = np.argsort(p)[::-1]\n",
    "        ids.append([i for i in idx[:k]])\n",
    "        ans.append(' '.join([i2c[i] for i in idx[:k]]))\n",
    "\n",
    "    return ans, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting on the entire data\n",
    "\n",
    "clf.fit(X, y)\n",
    "str_preds, _ = proba2labels(clf.predict_proba(test_data.drop(['label', 'fname'], axis = 1).values), i2c, k=3)\n",
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm['fname'] = audio_test_files\n",
    "subm['label'] = str_preds\n",
    "subm.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
